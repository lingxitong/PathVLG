# PathVLG <p align="center">
  <a href='https://scholar.google.com/citations?user=5lNlpagAAAAJ&hl=en'>
  <img src='https://img.shields.io/badge/Arxiv-2404.19759-A42C25?style=flat&logo=arXiv&logoColor=A42C25'></a> 
  <a href='https://github.com/lingxitong/PathVLG'>
  <img src='https://img.shields.io/badge/GitHub-Code-black?style=flat&logo=github&logoColor=white'></a> 
</p>

<img src="https://github.com/lingxitong/PathVLG/PathVLG_Logo.png"  width="290px" align="right" />
With the rapid development of large-scale vision–language models and multimodal learning techniques, pathology vision–language generation (VLG) has emerged as a transformative paradigm for bridging pathology image analysis with natural language understanding. This integration enables not only automated diagnostic prediction but also interpretable report generation, offering new possibilities for clinical decision support. However, existing pathology VLG studies often rely on fragmented implementations and heterogeneous architectures, which hinder accessibility, comparison, and reproducibility. We have developed the PathVLG library with the aim of providing a unified, lightweight, and extensible framework for building and evaluating pathology vision–language generation models.
